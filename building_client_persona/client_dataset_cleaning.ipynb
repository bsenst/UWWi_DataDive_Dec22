{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfnjQ2vK3Qb0"
      },
      "source": [
        "# Data Cleaning for clients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVCyRmxp3Qb8"
      },
      "source": [
        "First let's load the dataset and explore a little bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "GykxjYQH3Qb9",
        "outputId": "a2eb6b8b-3cf8-4e4c-acda-82bad797adc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\n75f4\\AppData\\Local\\Temp\\ipykernel_1136\\2050377758.py:6: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_client = pd.read_csv(CLIENTS_FILE)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Client_Id</th>\n",
              "      <th>Client_CreateStamp</th>\n",
              "      <th>Client_EditStamp</th>\n",
              "      <th>ClientOption_PreferredLanguageOfCaller</th>\n",
              "      <th>ClientSystem_PreferredLanguageOther</th>\n",
              "      <th>ClientAddressus_ClientAddressus_city</th>\n",
              "      <th>ClientAddressus_ClientAddressus_county</th>\n",
              "      <th>ClientAddressus_ClientAddressus_state</th>\n",
              "      <th>ClientAddressus_ClientAddressus_zip</th>\n",
              "      <th>ClientCustom_AgeOfPersonNeedingAssistance</th>\n",
              "      <th>ClientCustom_EthnicityOther</th>\n",
              "      <th>ClientOption_GenderOptionId</th>\n",
              "      <th>ClientOption_VeteranStatusOptionlist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-04-07T15:34:04.872169-05:00</td>\n",
              "      <td>2022-04-23T00:53:31.812322-05:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FOND DU LAC</td>\n",
              "      <td>FOND DU LAC</td>\n",
              "      <td>WI</td>\n",
              "      <td>54935.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-04-10T08:08:10.404723-05:00</td>\n",
              "      <td>2022-04-23T00:53:33.172375-05:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MADISON</td>\n",
              "      <td>DANE</td>\n",
              "      <td>WI</td>\n",
              "      <td>53705.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2017-04-10T08:21:14.98351-05:00</td>\n",
              "      <td>2022-02-28T19:01:21.95251-06:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54115.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2017-04-10T08:25:16.115921-05:00</td>\n",
              "      <td>2022-04-23T00:53:33.445243-05:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MENASHA</td>\n",
              "      <td>WINNEBAGO</td>\n",
              "      <td>WI</td>\n",
              "      <td>54952.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2017-04-10T08:42:59.367602-05:00</td>\n",
              "      <td>2022-04-23T00:53:33.678873-05:00</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NEENAH</td>\n",
              "      <td>WINNEBAGO</td>\n",
              "      <td>WI</td>\n",
              "      <td>54956.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Client_Id                Client_CreateStamp  \\\n",
              "0          1  2017-04-07T15:34:04.872169-05:00   \n",
              "1          2  2017-04-10T08:08:10.404723-05:00   \n",
              "2          3   2017-04-10T08:21:14.98351-05:00   \n",
              "3          4  2017-04-10T08:25:16.115921-05:00   \n",
              "4          5  2017-04-10T08:42:59.367602-05:00   \n",
              "\n",
              "                   Client_EditStamp ClientOption_PreferredLanguageOfCaller  \\\n",
              "0  2022-04-23T00:53:31.812322-05:00                                     []   \n",
              "1  2022-04-23T00:53:33.172375-05:00                                     []   \n",
              "2   2022-02-28T19:01:21.95251-06:00                                     []   \n",
              "3  2022-04-23T00:53:33.445243-05:00                                     []   \n",
              "4  2022-04-23T00:53:33.678873-05:00                                     []   \n",
              "\n",
              "  ClientSystem_PreferredLanguageOther ClientAddressus_ClientAddressus_city  \\\n",
              "0                                 NaN                          FOND DU LAC   \n",
              "1                                 NaN                              MADISON   \n",
              "2                                 NaN                                  NaN   \n",
              "3                                 NaN                              MENASHA   \n",
              "4                                 NaN                               NEENAH   \n",
              "\n",
              "  ClientAddressus_ClientAddressus_county  \\\n",
              "0                            FOND DU LAC   \n",
              "1                                   DANE   \n",
              "2                                    NaN   \n",
              "3                              WINNEBAGO   \n",
              "4                              WINNEBAGO   \n",
              "\n",
              "  ClientAddressus_ClientAddressus_state ClientAddressus_ClientAddressus_zip  \\\n",
              "0                                    WI                             54935.0   \n",
              "1                                    WI                             53705.0   \n",
              "2                                   NaN                             54115.0   \n",
              "3                                    WI                             54952.0   \n",
              "4                                    WI                             54956.0   \n",
              "\n",
              "   ClientCustom_AgeOfPersonNeedingAssistance ClientCustom_EthnicityOther  \\\n",
              "0                                        NaN                         NaN   \n",
              "1                                        NaN                         NaN   \n",
              "2                                        NaN                         NaN   \n",
              "3                                        NaN                         NaN   \n",
              "4                                        NaN                         NaN   \n",
              "\n",
              "  ClientOption_GenderOptionId ClientOption_VeteranStatusOptionlist  \n",
              "0                          []                                   []  \n",
              "1                          []                                   []  \n",
              "2                          []                                   []  \n",
              "3                          []                                   []  \n",
              "4                          []                                   []  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "CLIENTS_FILE = './uwwi_dataset_clients_v2.csv'     # updated to clients_v2.csv\n",
        "\n",
        "df_client = pd.read_csv(CLIENTS_FILE)\n",
        "df_client.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crxrpaB03QcF"
      },
      "source": [
        "First let's clean up the column names. This is the Client dataset, so it is not necessary to have every variable name start with \"Client\" or \"Client_\". Some columns also have \"Addressus\" repeated (which presumably stands for Address United States?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "AKBo2vn_3QcF",
        "outputId": "51dc3481-8c13-414f-f28f-24a8753235e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Id', 'CreateStamp', 'EditStamp', 'Option_PreferredLanguageOfCaller', 'System_PreferredLanguageOther', 'us_city', 'us_county', 'us_state', 'us_zip', 'Custom_AgeOfPersonNeedingAssistance', 'Custom_EthnicityOther', 'Option_GenderOptionId', 'Option_VeteranStatusOptionlist']\n"
          ]
        }
      ],
      "source": [
        "cols = df_client.columns\n",
        "\n",
        "# we do not need the Client Prefix\n",
        "new_col_names = [cols[i] for i in range(len(cols))]\n",
        "\n",
        "for i in range(len(cols)):\n",
        "    name = new_col_names[i]\n",
        "    name = name.removeprefix('Client') # redundant\n",
        "    name = name.removeprefix('Addressus') # redundant\n",
        "    name = name.removeprefix(\"_\")\n",
        "    name = name.removeprefix('Client') # redundant\n",
        "    name = name.removeprefix('Address') # redundant\n",
        "    new_col_names[i] = name\n",
        "    \n",
        "print(new_col_names)\n",
        "new_col_names = {cols[i]: new_col_names[i] for i in range(len(cols))}\n",
        "df_client = df_client.rename(columns=new_col_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpb28GcT3QcH"
      },
      "source": [
        "Let's go through columns one at a time and clean them up/reformat them. \n",
        "\n",
        "First, the Client_Id column looks like it's okay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "W4Eq7iuX3QcH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.all([isinstance(x,int) for x in df_client[\"Id\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNDtp6gU3QcI"
      },
      "source": [
        "Next the CreateStamp and EditStamp columns are complicated time strings. These could be converted to pandas timestamp objects here but this is not a current priority. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "UmMc6oRT3QcJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'datetime.datetime'>\n",
            "<class 'datetime.datetime'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 830450 entries, 0 to 830449\n",
            "Data columns (total 13 columns):\n",
            " #   Column                               Non-Null Count   Dtype  \n",
            "---  ------                               --------------   -----  \n",
            " 0   Id                                   830450 non-null  int64  \n",
            " 1   CreateStamp                          830450 non-null  object \n",
            " 2   EditStamp                            830450 non-null  object \n",
            " 3   Option_PreferredLanguageOfCaller     830450 non-null  object \n",
            " 4   System_PreferredLanguageOther        446 non-null     object \n",
            " 5   us_city                              798744 non-null  object \n",
            " 6   us_county                            797862 non-null  object \n",
            " 7   us_state                             799709 non-null  object \n",
            " 8   us_zip                               762323 non-null  object \n",
            " 9   Custom_AgeOfPersonNeedingAssistance  93127 non-null   float64\n",
            " 10  Custom_EthnicityOther                187 non-null     object \n",
            " 11  Option_GenderOptionId                830450 non-null  object \n",
            " 12  Option_VeteranStatusOptionlist       830450 non-null  object \n",
            "dtypes: float64(1), int64(1), object(11)\n",
            "memory usage: 82.4+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# for future - convert to Timestamp\n",
        "df_client['CreateStamp'] = pd.to_datetime(df_client['CreateStamp']) #, utc=True)         # Add utc=True to create column as datetime64[ns], otherwise will still be 'object'\n",
        "df_client['EditStamp'] = pd.to_datetime(df_client['EditStamp']) #, utc=True)\n",
        "\n",
        "# column values are now 'datetime.datetime' or 'pandas._libs.tslibs.timestamps.Timestamp'\n",
        "print(type(df_client['CreateStamp'][0]))\n",
        "print(type(df_client['EditStamp'][0]))\n",
        "\n",
        "# column is still 'object' if 'utc=True' not set above \n",
        "print(df_client.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKdg9uxW3QcK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rmoyIbz3QcL"
      },
      "source": [
        "Next the preferred language columns are lists and NaNs. These could be represented better but this is not a current priority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Fxtd9OI-3QcL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          702720\n",
            "English                   116272\n",
            "Spanish                     8170\n",
            "Undetermined                1627\n",
            "Declined                     609\n",
            "Other                        580\n",
            "American Sign Language       179\n",
            "Hmong                         91\n",
            "Chinese                       59\n",
            "French                        35\n",
            "Vietnamese                    31\n",
            "German                        23\n",
            "Russian                       21\n",
            "Korean                        17\n",
            "Italian                       11\n",
            "Tagalog                        5\n",
            "Name: Option_PreferredLanguageOfCaller, dtype: int64\n",
            "\n",
            "True     830004\n",
            "False       446\n",
            "Name: System_PreferredLanguageOther, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# for future - convert to List\n",
        "\n",
        "# removes brackets and single quotes from the values\n",
        "df_client[\"Option_PreferredLanguageOfCaller\"] = df_client[\"Option_PreferredLanguageOfCaller\"].str.strip('[]').str.strip(\"''\")\n",
        "print(df_client[\"Option_PreferredLanguageOfCaller\"].str.strip('[]').str.strip(\"''\").value_counts())\n",
        "\n",
        "# print null value counts\n",
        "print()\n",
        "print(df_client[\"System_PreferredLanguageOther\"].isnull().value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdVMAeGn3QcM"
      },
      "source": [
        "In the address blocks, we have some issues of inconsistent formatting, and numerically encoded zip codes. Let's change the zip codes to strings, and reformat the City and County names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "mdsFjw-G3QcN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['FOND DU LAC' 'MADISON' nan ... '53092' 'Coldwater' 'Taloga']\n",
            "['FOND DU LAC' 'DANE' nan ... 'Oneida ' 'Dewey' 'Branch']\n",
            "['54935' '53705' '54115' ... '49036' '33903' '73667']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(pd.unique(df_client[\"us_city\"]))\n",
        "print(pd.unique(df_client[\"us_county\"]))\n",
        "print(pd.unique(df_client[\"us_zip\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "wsVRWPd83QcN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['54935' '53705' '54115' ... '49036' '33903' '73667']\n"
          ]
        }
      ],
      "source": [
        "str_zips = [x if pd.isnull(x) else str(x)[0:5] for x in df_client[\"us_zip\"]]\n",
        "df_client[\"us_zip\"] = str_zips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuj8k6RQ3QcO"
      },
      "source": [
        "The US cities column requires more cleaning than can be effectively done during this time. It will be left in favor of the zips."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "AHoG025Q3QcO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<spellchecker.spellchecker.SpellChecker object at 0x000002B39D966B00>\n",
            "<built-in method title of str object at 0x000002B391540BB0>\n"
          ]
        }
      ],
      "source": [
        "# for future\n",
        "\n",
        "# some of these are all caps such as MALVERN\n",
        "# some of them are all lower such as new glarus\n",
        "# some of them zip codes such as 54952\n",
        "# some of them are just missing as nan\n",
        "# some of them are title case such as Stevens Point\n",
        "# some are abbrviations such as ATL\n",
        "# some are misspelled such as \"milaukee\" or \"miwlaukee\"\n",
        "\n",
        "'''\n",
        "# could try pyspellchecker\n",
        "\n",
        "import sys\n",
        "!{sys.executable} -m pip install pyspellchecker\n",
        "\n",
        "from spellchecker import SpellChecker\n",
        "checker = SpellChecker()\n",
        "print(checker)\n",
        "city = 'milwauke'\n",
        "print(checker.correction(city))\n",
        "'''\n",
        "\n",
        "# at least one is just an empty space\n",
        "# some are complete errors, such as \"Hispanic or Latino\"\n",
        "\n",
        "# the second half seems to be much better formatted\n",
        "# being all consistently title case\n",
        "# however it still contains some zip codes\n",
        "#[print(x) for x in pd.unique(df_client[\"us_city\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "MQ6x0Ne43QcP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# much of the same issues as with city\n",
        "# one is \"refused\"\n",
        "# several of these contain whole addresses, which is a privacy issue\n",
        "# these will need to be combed through with more precision than I can offer at the moment\n",
        "\n",
        "# [print(x) for x in pd.unique(df_client[\"us_county\"])]\n",
        "print(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOmvQzwz3QcQ"
      },
      "source": [
        "The states are just strings, except for one which is labeled as \"Array\" and should instead likely be nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "f4HzgxtR3QcQ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['WI', nan, 'MN', 'IA', 'AZ', 'IN', 'TX', 'IL', 'Array', 'AR', 'MO',\n",
              "       'FL', 'MA', 'MI', 'CA', 'OH', 'SD', 'TN', 'SC', 'ND', 'NE', 'CO',\n",
              "       'GA', 'WV', 'AL', 'OR', 'WA', 'KY', 'NV', 'VA', 'CT', 'ID', 'NC',\n",
              "       'MS', 'NY', 'LA', 'NH', 'DC', 'NJ', 'PA', 'OK', 'DE', 'PR', 'UT',\n",
              "       'KS', 'HI', 'VI', 'MT', 'RI', 'ME', 'MD', 'VT', 'WY', 'NM', 'AK',\n",
              "       'GU'], dtype=object)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.unique(df_client[\"us_state\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "EdNlyImH3QcR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([   729,    747,   5625,  11611,  19460,  30476,  35933,  41735,\n",
            "        63311,  74152,  80456,  81294,  92380,  93030, 107551, 121273,\n",
            "       129797, 136286, 138753, 147351, 148194], dtype=int64),)\n",
            "729\n",
            "747\n",
            "5625\n",
            "11611\n",
            "19460\n",
            "30476\n",
            "35933\n",
            "41735\n",
            "63311\n",
            "74152\n",
            "80456\n",
            "81294\n",
            "92380\n",
            "93030\n",
            "107551\n",
            "121273\n",
            "129797\n",
            "136286\n",
            "138753\n",
            "147351\n",
            "148194\n"
          ]
        }
      ],
      "source": [
        "ii = np.where(df_client.us_state==\"Array\")\n",
        "print(ii)\n",
        "for i in ii[0]:\n",
        "    print(i)\n",
        "    df_client.loc[i,\"us_state\"] = pd.NA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY14FE-p3QcS"
      },
      "source": [
        "This leaves remaining Age, Ethnicity, Gender, and Veteran, which I do not have time to tackle at the moment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJSDFrJ73QcT"
      },
      "source": [
        "### 2. Quick Choropleth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4zahLlI3QcT"
      },
      "source": [
        "We will use the Folium library to plot the zipcodes and their corresponding number of clients. For this task we will need a ZIPCODE GeoJSON file for Wisconsin. First let's calculate for each zip code the number of matching clients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "UdaWXyXu3QcU"
      },
      "outputs": [],
      "source": [
        "zip_codes = list(pd.unique(df_client.us_zip))\n",
        "num_clients = [0 for x in zip_codes]\n",
        "for z in df_client.us_zip:\n",
        "    if not pd.isnull(z):\n",
        "        num_clients[zip_codes.index(z)] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "oy59qZav3QcU"
      },
      "outputs": [],
      "source": [
        "d = {'zipcode': zip_codes, 'num_clients': num_clients}\n",
        "df_num_clients = pd.DataFrame(data=d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrFIAYSP3QcV"
      },
      "source": [
        "If we just plot the number of clients we will just get something that is a map of population, so what we really want is fraction of population served."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Pn_P8Xyv3QcV"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './wisconsin-zips.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\n75f4\\Downloads\\client_dataset_cleaning.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/n75f4/Downloads/client_dataset_cleaning.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ZIPS_FILE \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./wisconsin-zips.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/n75f4/Downloads/client_dataset_cleaning.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_pop \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(ZIPS_FILE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/n75f4/Downloads/client_dataset_cleaning.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_pop\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\n75f4\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\n75f4\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32mc:\\Users\\n75f4\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\n75f4\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32mc:\\Users\\n75f4\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\n75f4\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './wisconsin-zips.csv'"
          ]
        }
      ],
      "source": [
        "ZIPS_FILE = './wisconsin-zips.csv'\n",
        "\n",
        "df_pop = pd.read_csv(ZIPS_FILE)\n",
        "df_pop.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1xHBWqo3QcW"
      },
      "outputs": [],
      "source": [
        "df_pop[\"Zip Code\"] = [str(x) for x in df_pop[\"Zip Code\"]]\n",
        "df_pop[\"Population\"] = [int(x.replace(\",\",\"\")) for x in list(df_pop[\"Population\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkymLHTw3QcX"
      },
      "outputs": [],
      "source": [
        "pops = [df_pop[\"Population\"][list(df_pop[\"Zip Code\"]).index(x)] if x in list(df_pop[\"Zip Code\"]) and not pd.isnull(x) else pd.NA for x in zip_codes]\n",
        "d = {'zipcode': zip_codes, 'num_clients': num_clients, 'population': pops, 'clients_per_capita': np.array(num_clients)/(np.array(pops)+1),'residents_per_client': np.array(pops)/np.array(num_clients)}\n",
        "df_num_clients = pd.DataFrame(data=d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w08OJV2x3QcX"
      },
      "outputs": [],
      "source": [
        "df_num_clients.clients_per_capita"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW9sDGsV3QcX"
      },
      "outputs": [],
      "source": [
        "# Install folium library\n",
        "!pip install folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXRjfUov3QcY"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# GeoJSON file definition\n",
        "wisconsin_geojson = \"https://raw.githubusercontent.com/OpenDataDE/State-zip-code-GeoJSON/master/wi_wisconsin_zip_codes_geo.min.json\"\n",
        "\n",
        "\n",
        "# Creating the map centered at Wisconsin state\n",
        "m = folium.Map(location=[44.808444, -89.673194], \n",
        "               tiles=\"cartodbpositron\", \n",
        "               zoom_start=6.8)\n",
        "\n",
        "# Creating the Choropleth\n",
        "m.choropleth(geo_data=json.loads(requests.get(wisconsin_geojson).text),\n",
        "             data=df_num_clients[pd.notnull(df_num_clients.residents_per_client)],\n",
        "             columns=['zipcode', 'residents_per_client'],\n",
        "             key_on='feature.properties.ZCTA5CE10', \n",
        "             fill_color='YlOrRd', fill_opacity=1, line_opacity=0.2,\n",
        "             legend_name='Residents_Per_Client')\n",
        "\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkZPXcOU3QcZ"
      },
      "outputs": [],
      "source": [
        "m.save(outfile = './choropleth_underserved_areas.html' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62IBD8j3QcZ"
      },
      "source": [
        "### 4. Final thoughts of this dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7_emajz3QcZ"
      },
      "source": [
        "This map highlights in darker colors regions that have a high number of residents per client. Many of these regions overlap with regions of high need in the ADI choropleth. One conclusion is that those areas of overlap represent areas where there is a high degree of need, but where clients are not reaching out for support. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBpwgPBK3Qca"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5a61fa35cf28bcdd8032225c9d5ad3c5a0a6921e499b7e7f7f862a8897eaed27"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
